{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSLKmAKplhbx",
        "outputId": "9b4030b4-68ac-41d6-f8b2-3804f3b288f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.11.0 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7zVTji-Flt85"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "from typing import Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.utils.data\n",
        "import tqdm\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.nn import DataParallel\n",
        "from torchvision import transforms, datasets\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "from torch.distributions import Normal, Distribution, kl_divergence\n",
        "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aZ__GszJqxNw"
      },
      "outputs": [],
      "source": [
        "class IterableWrapper(IterableDataset):\n",
        "    \"\"\"\n",
        "    Turns a Dataset into an IterableDataset by endlessly yielding random samples from the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, delegate: Dataset):\n",
        "        self.delegate = delegate\n",
        "\n",
        "    def __iter__(self):\n",
        "        l = len(self.delegate)\n",
        "        while True:\n",
        "            for idx in random.sample(range(l), l):\n",
        "                yield self.delegate[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xmiVzZOqqtRC"
      },
      "outputs": [],
      "source": [
        "def iwae(x: t.Tensor, p_x_given_z: Distribution, q_z_given_x: Distribution, p_z: Distribution, z: t.Tensor):\n",
        "    \"\"\"\n",
        "        log(p(x)) >= logsumexp_{i=1}^N[ log(p(x|z_i)) + log(p(z_i)) - log(q(z_i|x))] - log(N)\n",
        "        x: bchw\n",
        "        q_z_given_x: bz\n",
        "        z: bnz\n",
        "        p_x_given_z: (bn)chw\n",
        "    \"\"\"\n",
        "    b, c, h, w = x.shape\n",
        "    b, n, zs = z.shape\n",
        "\n",
        "    x = (x.unsqueeze(1)\n",
        "         .expand((-1, n, -1, -1, -1))\n",
        "         .reshape(b * n, c, h, w)\n",
        "         )  # (bn)chw\n",
        "    logpx_given_z = p_x_given_z.log_prob(x).sum(dim=(1, 2, 3)).reshape((b, n))\n",
        "    logpz = p_z.log_prob(z).sum(dim=2)\n",
        "    logqz_given_x = q_z_given_x.log_prob(z.permute((1, 0, 2))).sum(dim=2).permute((1, 0))\n",
        "    logpx = (t.logsumexp(logpx_given_z + logpz - logqz_given_x, dim=1) - t.log(t.scalar_tensor(z.shape[1])))\n",
        "\n",
        "    return -logpx, None, None\n",
        "\n",
        "def elbo(x: t.Tensor, p_x_given_z: Distribution, q_z_given_x: Distribution, p_z: Distribution, z: t.Tensor):\n",
        "  \"\"\"\n",
        "      log p(x) >= E_q(z|x) [ log p(x|z) p(z) / q(z|x) ]\n",
        "      Reconstruction + KL divergence losses summed over all elements and batch\n",
        "      x: bchw\n",
        "      q_z_given_x: bz\n",
        "      z: bnz\n",
        "      p_x_given_z: (bn)chw\n",
        "  \"\"\"\n",
        "\n",
        "  b, c, h, w = x.shape\n",
        "  b, n, zs = z.shape\n",
        "\n",
        "  x = (x.unsqueeze(1)\n",
        "      .expand((-1, n, -1, -1, -1))\n",
        "      .reshape(-1, c, h, w)\n",
        "      )  # (bn)chw\n",
        "\n",
        "  logpx_given_z = p_x_given_z.log_prob(x).sum(dim=(1, 2, 3)).reshape((b, n)).mean(dim=1)\n",
        "  kld = kl_divergence(q_z_given_x, p_z).sum(dim=1)\n",
        "\n",
        "  reconstruction_loss = -logpx_given_z\n",
        "  kl_loss = kld\n",
        "\n",
        "  loss = reconstruction_loss + kl_loss\n",
        "  return loss, reconstruction_loss, kl_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pgyFHfSJqft-"
      },
      "outputs": [],
      "source": [
        "revision = os.environ.get(\"REVISION\") or \"%s\" % datetime.now()\n",
        "message = os.environ.get('MESSAGE')\n",
        "tensorboard_dir = 'tensorboard'\n",
        "flush_secs = 10\n",
        "\n",
        "def get_writers(name):\n",
        "    train_writer = SummaryWriter(tensorboard_dir + 'train', flush_secs=flush_secs)\n",
        "    test_writer = SummaryWriter(tensorboard_dir + 'test', flush_secs=flush_secs)\n",
        "    return train_writer, test_writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hvxwhedGo0QO"
      },
      "outputs": [],
      "source": [
        "class Model(t.nn.Module):\n",
        "\n",
        "  def train_batch(self) -> float:\n",
        "    raise NotImplemented()\n",
        "\n",
        "  def eval_batch(self) -> float:\n",
        "    raise NotImplemented()\n",
        "\n",
        "  def save(self, fn):\n",
        "    t.save({\n",
        "      'batch_idx': self.batch_idx,\n",
        "      'model_state_dict': self.state_dict(),\n",
        "      'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "    }, fn)\n",
        "\n",
        "  def load(self, fn):\n",
        "    checkpoint = t.load(fn, map_location=t.device(self.device))\n",
        "    self.batch_idx = checkpoint[\"batch_idx\"]\n",
        "    self.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DYZON3GnrQtn"
      },
      "outputs": [],
      "source": [
        "def train(model: Model, n_updates=int(1e6), eval_interval=1000):\n",
        "  best = float(\"inf\")\n",
        "  for i in tqdm.tqdm(range(n_updates)):\n",
        "    model.train_batch()\n",
        "    if (i + 1) % eval_interval == 0:\n",
        "      loss = model.eval_batch()\n",
        "      model.save(\"latest\")\n",
        "      if loss < best:\n",
        "        best = loss\n",
        "        model.save(\"best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B8joMi4xzgUo"
      },
      "outputs": [],
      "source": [
        "class DiscretizedMixtureLogitsDistribution(Distribution):\n",
        "    def __init__(self, nr_mix, logits):\n",
        "        super().__init__()\n",
        "        self.logits = logits\n",
        "        self.nr_mix = nr_mix\n",
        "        self._batch_shape = logits.shape\n",
        "\n",
        "    def log_prob(self, value):\n",
        "        return - discretized_mix_logistic_loss(value * 2 - 1, self.logits).unsqueeze(1)  # add channel dim for compatibility with loss functions expecting bchw\n",
        "\n",
        "    def sample(self):\n",
        "        return (sample_from_discretized_mix_logistic(self.logits, self.nr_mix) + 1) / 2\n",
        "\n",
        "    @property\n",
        "    def mean(self):\n",
        "        \"\"\"\n",
        "        Returns the mean of the distribution.\n",
        "        \"\"\"\n",
        "        return t.stack([self.sample() for _ in range(100)]).mean(dim=0)\n",
        "\n",
        "class DiscretizedMixtureLogits():\n",
        "\n",
        "    def __init__(self, nr_mix, **kwargs):\n",
        "        self.nr_mix = nr_mix\n",
        "\n",
        "    def __call__(self, logits):\n",
        "        return DiscretizedMixtureLogitsDistribution(self.nr_mix, logits)\n",
        "\n",
        "def log_sum_exp(x):\n",
        "    \"\"\" numerically stable log_sum_exp implementation that prevents overflow \"\"\"\n",
        "    # TF ordering\n",
        "    axis = len(x.size()) - 1\n",
        "    m, _ = torch.max(x, dim=axis)\n",
        "    m2, _ = torch.max(x, dim=axis, keepdim=True)\n",
        "    return m + torch.log(torch.sum(torch.exp(x - m2), dim=axis))\n",
        "\n",
        "def log_prob_from_logits(x):\n",
        "    \"\"\" numerically stable log_softmax implementation that prevents overflow \"\"\"\n",
        "    # TF ordering\n",
        "    axis = len(x.size()) - 1\n",
        "    m, _ = torch.max(x, dim=axis, keepdim=True)\n",
        "    return x - m - torch.log(torch.sum(torch.exp(x - m), dim=axis, keepdim=True))\n",
        "\n",
        "\n",
        "def discretized_mix_logistic_loss(x, l):\n",
        "    \"\"\" log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval \"\"\"\n",
        "    # Pytorch ordering\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    l = l.permute(0, 2, 3, 1)\n",
        "    xs = [int(y) for y in x.size()]\n",
        "    ls = [int(y) for y in l.size()]\n",
        "\n",
        "    # here and below: unpacking the params of the mixture of logistics\n",
        "    nr_mix = int(ls[-1] / 10)\n",
        "    logit_probs = l[:, :, :, :nr_mix]\n",
        "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 3])  # 3 for mean, scale, coef\n",
        "    means = l[:, :, :, :, :nr_mix]\n",
        "    # log_scales = torch.max(l[:, :, :, :, nr_mix:2 * nr_mix], -7.)\n",
        "    log_scales = torch.clamp(l[:, :, :, :, nr_mix:2 * nr_mix], min=-7.)\n",
        "\n",
        "    coeffs = torch.tanh(l[:, :, :, :, 2 * nr_mix:3 * nr_mix])\n",
        "    # here and below: getting the means and adjusting them based on preceding\n",
        "    # sub-pixels\n",
        "    x = x.contiguous()\n",
        "    x = x.unsqueeze(-1) + torch.zeros(xs + [nr_mix], device=x.device)\n",
        "    m2 = (means[:, :, :, 1, :] + coeffs[:, :, :, 0, :]\n",
        "          * x[:, :, :, 0, :]).view(xs[0], xs[1], xs[2], 1, nr_mix)\n",
        "\n",
        "    m3 = (means[:, :, :, 2, :] + coeffs[:, :, :, 1, :] * x[:, :, :, 0, :] +\n",
        "          coeffs[:, :, :, 2, :] * x[:, :, :, 1, :]).view(xs[0], xs[1], xs[2], 1, nr_mix)\n",
        "\n",
        "    means = torch.cat((means[:, :, :, 0, :].unsqueeze(3), m2, m3), dim=3)\n",
        "    centered_x = x - means\n",
        "    inv_stdv = torch.exp(-log_scales)\n",
        "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
        "    cdf_plus = torch.sigmoid(plus_in)\n",
        "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
        "    cdf_min = torch.sigmoid(min_in)\n",
        "    # log probability for edge case of 0 (before scaling)\n",
        "    log_cdf_plus = plus_in - F.softplus(plus_in)\n",
        "    # log probability for edge case of 255 (before scaling)\n",
        "    log_one_minus_cdf_min = -F.softplus(min_in)\n",
        "    cdf_delta = cdf_plus - cdf_min  # probability for all other cases\n",
        "    mid_in = inv_stdv * centered_x\n",
        "    # log probability in the center of the bin, to be used in extreme cases\n",
        "    # (not actually used in our code)\n",
        "    log_pdf_mid = mid_in - log_scales - 2. * F.softplus(mid_in)\n",
        "\n",
        "    # now select the right output: left edge case, right edge case, normal\n",
        "    # case, extremely low prob case (doesn't actually happen for us)\n",
        "\n",
        "    # this is what we are really doing, but using the robust version below for extreme cases in other applications and to avoid NaN issue with tf.select()\n",
        "    # log_probs = tf.select(x < -0.999, log_cdf_plus, tf.select(x > 0.999, log_one_minus_cdf_min, tf.log(cdf_delta)))\n",
        "\n",
        "    # robust version, that still works if probabilities are below 1e-5 (which never happens in our code)\n",
        "    # tensorflow backpropagates through tf.select() by multiplying with zero instead of selecting: this requires use to use some ugly tricks to avoid potential NaNs\n",
        "    # the 1e-12 in tf.maximum(cdf_delta, 1e-12) is never actually used as output, it's purely there to get around the tf.select() gradient issue\n",
        "    # if the probability on a sub-pixel is below 1e-5, we use an approximation\n",
        "    # based on the assumption that the log-density is constant in the bin of\n",
        "    # the observed sub-pixel value\n",
        "\n",
        "    inner_inner_cond = (cdf_delta > 1e-5).float()\n",
        "    inner_inner_out = inner_inner_cond * torch.log(torch.clamp(cdf_delta, min=1e-12)) + (1. - inner_inner_cond) * (\n",
        "            log_pdf_mid - np.log(127.5))\n",
        "    inner_cond = (x > 0.999).float()\n",
        "    inner_out = inner_cond * log_one_minus_cdf_min + (1. - inner_cond) * inner_inner_out\n",
        "    cond = (x < -0.999).float()\n",
        "    log_probs = cond * log_cdf_plus + (1. - cond) * inner_out\n",
        "    log_probs = torch.sum(log_probs, dim=3) + log_prob_from_logits(logit_probs)\n",
        "\n",
        "    return - log_sum_exp(log_probs)\n",
        "\n",
        "def to_one_hot(tensor, n, fill_with=1.):\n",
        "    # we perform one hot encore with respect to the last axis\n",
        "    one_hot = torch.FloatTensor(tensor.size() + (n,)).zero_()\n",
        "    if tensor.is_cuda: one_hot = one_hot.cuda()\n",
        "    one_hot.scatter_(len(tensor.size()), tensor.unsqueeze(-1), fill_with)\n",
        "    return Variable(one_hot)\n",
        "\n",
        "\n",
        "def sample_from_discretized_mix_logistic(l, nr_mix):\n",
        "    # Pytorch ordering\n",
        "    l = l.permute(0, 2, 3, 1)\n",
        "    ls = [int(y) for y in l.size()]\n",
        "    xs = ls[:-1] + [3]\n",
        "\n",
        "    # unpack parameters\n",
        "    logit_probs = l[:, :, :, :nr_mix]\n",
        "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 3])\n",
        "    # sample mixture indicator from softmax\n",
        "    temp = torch.FloatTensor(logit_probs.size())\n",
        "    if l.is_cuda: temp = temp.cuda()\n",
        "    temp.uniform_(1e-5, 1. - 1e-5)\n",
        "    temp = logit_probs.data - torch.log(- torch.log(temp))\n",
        "    _, argmax = temp.max(dim=3)\n",
        "\n",
        "    one_hot = to_one_hot(argmax, nr_mix)\n",
        "    sel = one_hot.view(xs[:-1] + [1, nr_mix])\n",
        "    # select logistic parameters\n",
        "    means = torch.sum(l[:, :, :, :, :nr_mix] * sel, dim=4)\n",
        "    log_scales = torch.clamp(torch.sum(\n",
        "        l[:, :, :, :, nr_mix:2 * nr_mix] * sel, dim=4), min=-7.)\n",
        "    coeffs = torch.sum(torch.tanh(\n",
        "        l[:, :, :, :, 2 * nr_mix:3 * nr_mix]) * sel, dim=4)\n",
        "    # sample from logistic & clip to interval\n",
        "    # we don't actually round to the nearest 8bit value when sampling\n",
        "    u = torch.FloatTensor(means.size())\n",
        "    if l.is_cuda: u = u.cuda()\n",
        "    u.uniform_(1e-5, 1. - 1e-5)\n",
        "    u = Variable(u)\n",
        "    x = means + torch.exp(log_scales) * (torch.log(u) - torch.log(1. - u))\n",
        "    x0 = torch.clamp(torch.clamp(x[:, :, :, 0], min=-1.), max=1.)\n",
        "    x1 = torch.clamp(torch.clamp(\n",
        "        x[:, :, :, 1] + coeffs[:, :, :, 0] * x0, min=-1.), max=1.)\n",
        "    x2 = torch.clamp(torch.clamp(\n",
        "        x[:, :, :, 2] + coeffs[:, :, :, 1] * x0 + coeffs[:, :, :, 2] * x1, min=-1.), max=1.)\n",
        "\n",
        "    out = torch.cat([x0.view(xs[:-1] + [1]), x1.view(xs[:-1] + [1]), x2.view(xs[:-1] + [1])], dim=3)\n",
        "    # put back in Pytorch ordering\n",
        "    out = out.permute(0, 3, 1, 2)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zYqP_7m_zT3I"
      },
      "outputs": [],
      "source": [
        "n_mixtures = 1\n",
        "\n",
        "def state_to_dist(state):\n",
        "    return DiscretizedMixtureLogitsDistribution(n_mixtures, state[:, :n_mixtures * 10, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XOWIglOIlRWA"
      },
      "outputs": [],
      "source": [
        "class VAE(Model):\n",
        "    \n",
        "  def __init__(self,\n",
        "                 h: int,\n",
        "                 w: int,\n",
        "                 n_channels: int,\n",
        "                 z_size: int,\n",
        "                 encoder: t.nn.Module,\n",
        "                 decoder_linear: t.nn.Module, \n",
        "                 decoder: t.nn.Module,\n",
        "                 train_data: Dataset,\n",
        "                 val_data: Dataset,\n",
        "                 test_data: Dataset,\n",
        "                 states_to_dist,\n",
        "                 batch_size: int,\n",
        "                 p_update: float,\n",
        "                 min_steps: int,\n",
        "                 max_steps: int, \n",
        "                 encoder_hid\n",
        "                 ):\n",
        "    super(Model, self).__init__()\n",
        "    self.h = h # height of the image\n",
        "    self.w = w # width of the image\n",
        "    self.n_channels = n_channels # number of channels of the image\n",
        "    self.state_to_dist = states_to_dist # function that turns a set of state to a distribution\n",
        "    self.z_size = z_size # dimensionality of the latent space\n",
        "    self.device = \"cuda\" if t.cuda.is_available() else \"cpu\" # check if we have a gpu\n",
        "\n",
        "    self.encoder = encoder # define the encoder\n",
        "    self.decoder_linear = decoder_linear # define the linear decoder\n",
        "    self.decoder = decoder # define the decoder\n",
        "    self.unflatten = nn.Unflatten(-1, (encoder_hid * 2 ** 5, h // 16, w // 16))\n",
        "    self.p_z = Normal(t.zeros(self.z_size, device=self.device), t.ones(self.z_size, device=self.device)) # defines a 0 mean prior distribution for the latent space\n",
        "\n",
        "    self.test_set = test_data # appoint the test data\n",
        "    self.train_loader = iter(DataLoader(IterableWrapper(train_data), batch_size=batch_size, pin_memory=True)) # initialize a data loader for the training data\n",
        "    self.val_loader = iter(DataLoader(IterableWrapper(val_data), batch_size=batch_size, pin_memory=True)) # initialize a data loader for the validation data\n",
        "    self.train_writer, self.test_writer = get_writers(\"vae\") # initialize a writer for the tensorboard\n",
        "\n",
        "    print(self) # report the model\n",
        "    total = sum(p.numel() for p in self.parameters()) # calculate the total number of learnable parameters\n",
        "    for n, p in self.named_parameters():\n",
        "        print(n, p.shape, p.numel(), \"%.1f\" % (p.numel() / total * 100)) # report information about the layers of the encoder and the decoder\n",
        "    print(\"Total: %d\" % total) # print the total number of learnable parameters\n",
        "\n",
        "    self.to(self.device) # move the pytorch tensor to the gpu if possible\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=1e-4) # initialize the ADAM optimizer\n",
        "    self.batch_idx = 0 # initalize the batch index to 0\n",
        "\n",
        "  def train_batch(self):\n",
        "    self.train(True) # set the training mode to True\n",
        "\n",
        "    self.optimizer.zero_grad() # remove prior gradients from the mmodel\n",
        "    x, y = next(self.train_loader) # load a batch of training data\n",
        "    loss, z, p_x_given_z, recon_loss, kl_loss, state = self.forward(x, 1, elbo) # forward the batch of training data throught the network\n",
        "    loss.mean().backward() # gradient of the loss with respect to all the model parameters\n",
        "\n",
        "    t.nn.utils.clip_grad_norm_(self.parameters(), 1.0, error_if_nonfinite=True) # clip the gradient to a range of [-1, 1] \n",
        "\n",
        "    self.optimizer.step() # use the clip gradient to perform a step of backpropagation on the parameters of the model\n",
        "\n",
        "    if self.batch_idx % 100 == 0: \n",
        "        self.report(self.train_writer, state, loss, recon_loss, kl_loss) # report on the results every 100 steps\n",
        "\n",
        "    self.batch_idx += 1 # increment the batch index\n",
        "    return loss.mean().item() \n",
        "    \n",
        "  def eval_batch(self):\n",
        "    self.train(False) # set the training mode to False\n",
        "    with t.no_grad():\n",
        "        x, y = next(self.val_loader) # load a batch of validation data\n",
        "        loss, z, p_x_given_z, recon_loss, kl_loss, state = self.forward(x, 1, iwae) # forward the batch of validation data throught the network\n",
        "        self.report(self.test_writer, state, loss, recon_loss, kl_loss) # report on the results\n",
        "    return loss.mean().item()\n",
        "\n",
        "  def test(self, n_iw_samples):\n",
        "      self.train(False) # set the training mode to False\n",
        "      with t.no_grad():\n",
        "          total_loss = 0.0 # initialize the total loss\n",
        "          for x, y in tqdm.tqdm(self.test_set): # iterate over the whole test set \n",
        "              loss, z, p_x_given_z, recon_loss, kl_loss, states = self.forward(x, n_iw_samples, iwae) # forward a single sample of the testing data through the network \n",
        "              total_loss += loss.mean().item() # add the mean of the loss to the total loss\n",
        "\n",
        "      print(total_loss / len(self.test_set)) # return the average loss of the test set\n",
        "\n",
        "  def encode(self, x) -> Distribution:  # q(z|x)\n",
        "      q = self.encoder(x) # run the encoder and retunrs a vector of size 2 * the latent space \n",
        "      loc = q[:, :self.z_size] # mean of the latent distribution\n",
        "      logsigma = q[:, self.z_size:] # log variance of the latent ditribution\n",
        "      return Normal(loc=loc, scale=t.exp(logsigma)) # return a normal distribution with the mean and variance received from the encoder\n",
        "\n",
        "  def decode(self, z: t.Tensor) -> Tuple[Distribution, Sequence[t.Tensor]]:  # p(x|z)\n",
        "      flat_features = self.decoder_linear(z)\n",
        "      flat_features = t.squeeze(flat_features)\n",
        "      unflattened = self.unflatten(flat_features)\n",
        "      return self.decoder(unflattened) # run the decoder\n",
        "\n",
        "  def forward(self, x, n_samples, loss_fn):\n",
        "      x = x.to(self.device) # move the pytorch tensor to the gpu if possible\n",
        "\n",
        "      q_z_given_x = self.encode(x) # run the encoder to receive the conditional latent distribution\n",
        "      z = q_z_given_x.rsample((n_samples,)).permute((1, 0, 2)) # sample from the conditional latent distribution\n",
        "\n",
        "      state = self.decode(z) # decode the sample\n",
        "      print(state.shape)\n",
        "      p_x_given_z = self.state_to_dist(state) # get the conditional probability distribution using the state\n",
        "\n",
        "      loss, recon_loss, kl_loss = loss_fn(x, p_x_given_z, q_z_given_x, self.p_z, z) # calculate the loss using the two distributions\n",
        "\n",
        "      return loss, z, p_x_given_z, recon_loss, kl_loss, state\n",
        "\n",
        "  def report(self, writer: SummaryWriter, recon_state, loss, recon_loss, kl_loss):\n",
        "      writer.add_scalar('loss', loss.mean().item(), self.batch_idx)\n",
        "      writer.add_scalar('bpd', loss.mean().item() / (np.log(2) * self.n_channels * self.h * self.w), self.batch_idx)\n",
        "      writer.add_scalar('pool_size', len(self.pool), self.batch_idx)\n",
        "\n",
        "      if recon_loss is not None:\n",
        "          writer.add_scalar('recon_loss', recon_loss.mean().item(), self.batch_idx)\n",
        "      if kl_loss is not None:\n",
        "          writer.add_scalar('kl_loss', kl_loss.mean().item(), self.batch_idx)\n",
        "\n",
        "      with t.no_grad():\n",
        "          # samples\n",
        "          samples = self.p_z.sample((8,)).view(8, -1, 1, 1).expand(8, -1, self.h, self.w).to(self.device)\n",
        "          states = self.decode(samples) # decode the samples into images\n",
        "          writer.add_images(\"samples/samples\", states, self.batch_idx)\n",
        "  \n",
        "          # Reconstructions\n",
        "          writer.add_images(\"recons/samples\", recon_state.detach(), self.batch_idx)\n",
        "\n",
        "      writer.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TZXvC93TJd4G"
      },
      "outputs": [],
      "source": [
        "z_size = 256\n",
        "vae_hid = 128\n",
        "n_mixtures = 1\n",
        "batch_size = 32\n",
        "dmg_size = 16\n",
        "p_update = 1.0\n",
        "min_steps, max_steps = 64, 128\n",
        "\n",
        "filter_size = 5\n",
        "pad = filter_size // 2\n",
        "encoder_hid = 32\n",
        "h = w = 32\n",
        "n_channels = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sTZjhtoKJCOW"
      },
      "outputs": [],
      "source": [
        "encoder = nn.Sequential(\n",
        "    nn.Conv2d(n_channels, encoder_hid * 2 ** 0, filter_size, padding=pad), nn.ELU(),  # (bs, 32, h, w)\n",
        "    nn.Conv2d(encoder_hid * 2 ** 0, encoder_hid * 2 ** 1, filter_size, padding=pad, stride=2), nn.ELU(),  # (bs, 64, h//2, w//2)\n",
        "    nn.Conv2d(encoder_hid * 2 ** 1, encoder_hid * 2 ** 2, filter_size, padding=pad, stride=2), nn.ELU(),  # (bs, 128, h//4, w//4)\n",
        "    nn.Conv2d(encoder_hid * 2 ** 2, encoder_hid * 2 ** 3, filter_size, padding=pad, stride=2), nn.ELU(),  # (bs, 256, h//8, w//8)\n",
        "    nn.Conv2d(encoder_hid * 2 ** 3, encoder_hid * 2 ** 4, filter_size, padding=pad, stride=2), nn.ELU(),  # (bs, 512, h//16, w//16),\n",
        "    nn.Flatten(),  # (bs, 512*h//16*w//16)\n",
        "    nn.Linear(encoder_hid * (2 ** 4) * h // 16 * w // 16, 2 * z_size),\n",
        ")\n",
        "\n",
        "decoder_linear = nn.Sequential(\n",
        "    nn.Linear(z_size, (encoder_hid * 2 ** 5) * 4), nn.ELU()\n",
        ")\n",
        "\n",
        "decoder = nn.Sequential(\n",
        "    nn.ConvTranspose2d(encoder_hid * 2 ** 5, encoder_hid * 2 ** 4, filter_size, padding=pad, stride=2, output_padding=1), nn.ELU(),\n",
        "    nn.ConvTranspose2d(encoder_hid * 2 ** 4, encoder_hid * 2 ** 3, filter_size, padding=pad, stride=2, output_padding=1), nn.ELU(),\n",
        "    nn.ConvTranspose2d(encoder_hid * 2 ** 3, encoder_hid * 2 ** 2, filter_size, padding=pad, stride=2, output_padding=1), nn.ELU(),\n",
        "    nn.ConvTranspose2d(encoder_hid * 2 ** 2, encoder_hid * 2 ** 1, filter_size, padding=pad, stride=2, output_padding=1), nn.ELU(),\n",
        "    nn.ConvTranspose2d(encoder_hid * 2 ** 1, encoder_hid * 2 ** 0, filter_size, padding=pad, stride=2, output_padding=1), nn.ELU(),\n",
        "    nn.ConvTranspose2d(encoder_hid * 2 ** 0, 10, filter_size, padding=pad)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nbTU70U6UgAl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Dataset can be found and downloaded at \"https://www.kaggle.com/datasets/kvpratama/pokemon-images-dataset/download\"\n",
        "\n",
        "data_dir = os.path.join(os.getcwd(), \"dataset\")\n",
        "\n",
        "def to_alpha(x):\n",
        "  return torch.clip(x[3:4,...], 0.0, 1.0)\n",
        "\n",
        "def to_rgb(x):\n",
        "  # assume rgb premultiplied by alpha\n",
        "  rgb, a = x[:3,...], to_alpha(x)\n",
        "  return 1.0-a+rgb\n",
        "\n",
        "class PokemonIMG(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.filenames = os.listdir(data_dir)\n",
        "        self.h = self.w = 32\n",
        "        self.transform = transforms.Compose([transforms.Resize((self.h, self.w)), transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = os.path.join(data_dir,\n",
        "                                self.filenames[index])\n",
        "        image = self.transform(Image.fromarray(io.imread(img_name)))\n",
        "        #train_set[0][0][:3,:,:] *= train_set[0][0][3:,:,:]\n",
        "        image[:3,...] *= image[3:,...]\n",
        "        return to_rgb(image), 0  # placeholder label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ad2pLvvrX_BR",
        "outputId": "ea22f306-0fb4-473c-a20d-329b7505850c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAE(\n",
            "  (encoder): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ELU(alpha=1.0)\n",
            "    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "    (3): ELU(alpha=1.0)\n",
            "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "    (5): ELU(alpha=1.0)\n",
            "    (6): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "    (7): ELU(alpha=1.0)\n",
            "    (8): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "    (9): ELU(alpha=1.0)\n",
            "    (10): Flatten(start_dim=1, end_dim=-1)\n",
            "    (11): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  )\n",
            "  (decoder_linear): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=4096, bias=True)\n",
            "    (1): ELU(alpha=1.0)\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): ConvTranspose2d(1024, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
            "    (1): ELU(alpha=1.0)\n",
            "    (2): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
            "    (3): ELU(alpha=1.0)\n",
            "    (4): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
            "    (5): ELU(alpha=1.0)\n",
            "    (6): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
            "    (7): ELU(alpha=1.0)\n",
            "    (8): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
            "    (9): ELU(alpha=1.0)\n",
            "    (10): ConvTranspose2d(32, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (unflatten): Unflatten(dim=-1, unflattened_size=(1024, 2, 2))\n",
            ")\n",
            "encoder.0.weight torch.Size([32, 3, 5, 5]) 2400 0.0\n",
            "encoder.0.bias torch.Size([32]) 32 0.0\n",
            "encoder.2.weight torch.Size([64, 32, 5, 5]) 51200 0.2\n",
            "encoder.2.bias torch.Size([64]) 64 0.0\n",
            "encoder.4.weight torch.Size([128, 64, 5, 5]) 204800 0.9\n",
            "encoder.4.bias torch.Size([128]) 128 0.0\n",
            "encoder.6.weight torch.Size([256, 128, 5, 5]) 819200 3.4\n",
            "encoder.6.bias torch.Size([256]) 256 0.0\n",
            "encoder.8.weight torch.Size([512, 256, 5, 5]) 3276800 13.7\n",
            "encoder.8.bias torch.Size([512]) 512 0.0\n",
            "encoder.11.weight torch.Size([512, 2048]) 1048576 4.4\n",
            "encoder.11.bias torch.Size([512]) 512 0.0\n",
            "decoder_linear.0.weight torch.Size([4096, 256]) 1048576 4.4\n",
            "decoder_linear.0.bias torch.Size([4096]) 4096 0.0\n",
            "decoder.0.weight torch.Size([1024, 512, 5, 5]) 13107200 54.8\n",
            "decoder.0.bias torch.Size([512]) 512 0.0\n",
            "decoder.2.weight torch.Size([512, 256, 5, 5]) 3276800 13.7\n",
            "decoder.2.bias torch.Size([256]) 256 0.0\n",
            "decoder.4.weight torch.Size([256, 128, 5, 5]) 819200 3.4\n",
            "decoder.4.bias torch.Size([128]) 128 0.0\n",
            "decoder.6.weight torch.Size([128, 64, 5, 5]) 204800 0.9\n",
            "decoder.6.bias torch.Size([64]) 64 0.0\n",
            "decoder.8.weight torch.Size([64, 32, 5, 5]) 51200 0.2\n",
            "decoder.8.bias torch.Size([32]) 32 0.0\n",
            "decoder.10.weight torch.Size([32, 10, 5, 5]) 8000 0.0\n",
            "decoder.10.bias torch.Size([10]) 10 0.0\n",
            "Total: 23925354\n",
            "torch.Size([32, 10, 64, 64])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class '__main__.DiscretizedMixtureLogitsDistribution'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  'with `validate_args=False` to turn off validation.')\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9c8489315ff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_linear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_to_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-dbe3ff3b727d>\u001b[0m in \u001b[0;36meval_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load a batch of validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_x_given_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwae\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward the batch of validation data throught the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# report on the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-dbe3ff3b727d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, n_samples, loss_fn)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mp_x_given_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get the conditional probability distribution using the state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_x_given_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_z_given_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate the loss using the two distributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_x_given_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-0166dac01a3f>\u001b[0m in \u001b[0;36miwae\u001b[0;34m(x, p_x_given_z, q_z_given_x, p_z, z)\u001b[0m\n\u001b[1;32m     14\u001b[0m          \u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m          )  # (bn)chw\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlogpx_given_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_x_given_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mlogpz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mlogqz_given_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_z_given_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-8fb1d597fa41>\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdiscretized_mix_logistic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add channel dim for compatibility with loss functions expecting bchw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-8fb1d597fa41>\u001b[0m in \u001b[0;36mdiscretized_mix_logistic_loss\u001b[0;34m(x, l)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mnr_mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mlogit_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnr_mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_mix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnr_mix\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 3 for mean, scale, coef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnr_mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# log_scales = torch.max(l[:, :, :, :, nr_mix:2 * nr_mix], -7.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 32, 32, 3, 3]' is invalid for input of size 1179648"
          ]
        }
      ],
      "source": [
        "z_size = 256\n",
        "n_mixtures = 1\n",
        "batch_size = 32\n",
        "p_update = 1.0\n",
        "min_steps, max_steps = 64, 128\n",
        "\n",
        "filter_size = 5\n",
        "pad = filter_size // 2\n",
        "encoder_hid = 32\n",
        "h = w = 32\n",
        "n_channels = 3\n",
        "\n",
        "\n",
        "def state_to_dist(state):\n",
        "    return DiscretizedMixtureLogitsDistribution(n_mixtures, state[:, :n_mixtures * 10, :, :])\n",
        "\n",
        "dset = PokemonIMG()\n",
        "\n",
        "num_samples = len(dset)\n",
        "train_split = 0.7\n",
        "val_split = 0.2\n",
        "test_split = 0.1\n",
        "\n",
        "num_train = math.floor(num_samples*train_split)\n",
        "num_val = math.floor(num_samples*val_split)\n",
        "num_test = math.floor(num_samples*test_split)\n",
        "num_test = num_test + (num_samples - num_train - num_val - num_test)\n",
        "\n",
        "train_set, val_set, test_set = t.utils.data.random_split(dset, [num_train, num_val, num_test])\n",
        "\n",
        "vae = VAE(h, w, n_channels, z_size, encoder, decoder_linear, decoder, train_set, val_set, test_set, state_to_dist, batch_size, p_update, min_steps, max_steps, encoder_hid)\n",
        "vae.eval_batch()\n",
        "train(vae, n_updates=100_000, eval_interval=100)\n",
        "vae.test(128)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "VAE_pokemon.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
