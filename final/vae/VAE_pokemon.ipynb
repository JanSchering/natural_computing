{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSLKmAKplhbx",
        "outputId": "5833cfaa-0f5d-4828-d9fc-fcab57e818c5"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.11.0 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7zVTji-Flt85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jsche\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "import torch as t\n",
        "\n",
        "from data import PokemonIMG\n",
        "from distributions import DiscretizedMixtureLogitsDistribution\n",
        "from train import train\n",
        "from vae import VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zYqP_7m_zT3I"
      },
      "outputs": [],
      "source": [
        "n_mixtures = 1\n",
        "\n",
        "# input 'state' should have as shape (batch_size, z_space, height, width)\n",
        "def state_to_dist(state):\n",
        "    return DiscretizedMixtureLogitsDistribution(n_mixtures, state[:, :n_mixtures * 10, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TZXvC93TJd4G"
      },
      "outputs": [],
      "source": [
        "z_size = 256\n",
        "vae_hid = 128\n",
        "n_mixtures = 1\n",
        "batch_size = 32\n",
        "dmg_size = 16\n",
        "p_update = 1.0\n",
        "min_steps, max_steps = 64, 128\n",
        "\n",
        "encoder_hid = 32\n",
        "h = w = 32\n",
        "n_channels = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "dset = PokemonIMG()\n",
        "\n",
        "num_samples = len(dset)\n",
        "train_split = 0.7\n",
        "val_split = 0.2\n",
        "test_split = 0.1\n",
        "\n",
        "num_train = math.floor(num_samples*train_split)\n",
        "num_val = math.floor(num_samples*val_split)\n",
        "num_test = math.floor(num_samples*test_split)\n",
        "num_test = num_test + (num_samples - num_train - num_val - num_test)\n",
        "\n",
        "train_set, val_set, test_set = t.utils.data.random_split(dset, [num_train, num_val, num_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAE(\n",
            "  (conv2d1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2d2): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "  (conv2d3): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "  (conv2d4): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "  (conv2d5): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "  (elu): ELU(alpha=1.0)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (dec_lin): Linear(in_features=256, out_features=4096, bias=True)\n",
            "  (conv_t2d1): ConvTranspose2d(1024, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
            "  (conv_t2d2): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
            "  (conv_t2d3): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
            "  (conv_t2d4): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
            "  (conv_t2d5): ConvTranspose2d(64, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (unflatten): Unflatten(dim=-1, unflattened_size=(1024, 2, 2))\n",
            ")\n",
            "conv2d1.weight torch.Size([32, 3, 5, 5]) 2400 0.0\n",
            "conv2d1.bias torch.Size([32]) 32 0.0\n",
            "conv2d2.weight torch.Size([64, 32, 5, 5]) 51200 0.2\n",
            "conv2d2.bias torch.Size([64]) 64 0.0\n",
            "conv2d3.weight torch.Size([128, 64, 5, 5]) 204800 0.9\n",
            "conv2d3.bias torch.Size([128]) 128 0.0\n",
            "conv2d4.weight torch.Size([256, 128, 5, 5]) 819200 3.4\n",
            "conv2d4.bias torch.Size([256]) 256 0.0\n",
            "conv2d5.weight torch.Size([512, 256, 5, 5]) 3276800 13.7\n",
            "conv2d5.bias torch.Size([512]) 512 0.0\n",
            "linear.weight torch.Size([512, 2048]) 1048576 4.4\n",
            "linear.bias torch.Size([512]) 512 0.0\n",
            "dec_lin.weight torch.Size([4096, 256]) 1048576 4.4\n",
            "dec_lin.bias torch.Size([4096]) 4096 0.0\n",
            "conv_t2d1.weight torch.Size([1024, 512, 5, 5]) 13107200 54.9\n",
            "conv_t2d1.bias torch.Size([512]) 512 0.0\n",
            "conv_t2d2.weight torch.Size([512, 256, 5, 5]) 3276800 13.7\n",
            "conv_t2d2.bias torch.Size([256]) 256 0.0\n",
            "conv_t2d3.weight torch.Size([256, 128, 5, 5]) 819200 3.4\n",
            "conv_t2d3.bias torch.Size([128]) 128 0.0\n",
            "conv_t2d4.weight torch.Size([128, 64, 5, 5]) 204800 0.9\n",
            "conv_t2d4.bias torch.Size([64]) 64 0.0\n",
            "conv_t2d5.weight torch.Size([64, 10, 5, 5]) 16000 0.1\n",
            "conv_t2d5.bias torch.Size([10]) 10 0.0\n",
            "Total: 23882122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jsche\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\distributions\\distribution.py:44: UserWarning: <class 'distributions.DiscretizedMixtureLogitsDistribution'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n",
            "100%|██████████| 100000/100000 [3:18:10<00:00,  8.41it/s] \n"
          ]
        }
      ],
      "source": [
        "vae = VAE(h, w, n_channels, z_size, train_set, val_set, test_set, state_to_dist, batch_size, p_update, min_steps, max_steps, encoder_hid)\n",
        "vae.eval_batch()\n",
        "train(vae, n_updates=100_000, eval_interval=100, suffix=\"VAE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vae.test(128)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "VAE_pokemon.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d457bbfc426ef2d36a37fd2ab82784599b6e7b389a7b568386df2942100916c1"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('torch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
